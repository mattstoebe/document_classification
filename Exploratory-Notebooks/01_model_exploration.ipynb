{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, multilabel_confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import joblib, json, matplotlib.pyplot as plt, seaborn as sns\n",
    "\n",
    "import numpy as np, pandas as pd, joblib\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing   import MultiLabelBinarizer\n",
    "from sklearn.multiclass      import OneVsRestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier \n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "\n",
    "RANDOM = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\"../data/craft-ml-data-train.jsonl\", lines=True)\n",
    "# train_df = train_df.explode(\"labels\")\n",
    "X_train = train_df[\"text\"]\n",
    "y_train = train_df[\"labels\"].str[0]\n",
    "\n",
    "test_df = pd.read_json(\"../data/craft-ml-data-test.jsonl\", lines=True)\n",
    "# test_df = test_df.explode(\"labels\")\n",
    "X_test = test_df[\"text\"]\n",
    "y_test = test_df[\"labels\"].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Class Baseline\n",
    "\n",
    "I want to see how hard this is under a one label process then move to two labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tfidf = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_df=0.9,\n",
    "    min_df=2,\n",
    "    ngram_range=(1,2),\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "char_tfidf = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(3,5),\n",
    "    min_df=2,\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(vec, clf, k_best=None):\n",
    "    steps = [(\"vec\", vec)]\n",
    "    steps += [(\"clf\", clf)]\n",
    "    return Pipeline(steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogReg_word ===\n",
      "0.5125\n",
      "\n",
      "=== SVM_word ===\n",
      "0.5125\n",
      "\n",
      "=== CompNB_word ===\n",
      "0.3375\n",
      "\n",
      "=== LogReg_word+char ===\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "baselines = {\n",
    "    \"LogReg_word\" : make_pipeline(\n",
    "        word_tfidf,\n",
    "        LogisticRegression(max_iter=1000, class_weight=\"balanced\", C=2.0)\n",
    "    ),\n",
    "    \"SVM_word\"    : make_pipeline(\n",
    "        word_tfidf,\n",
    "        LinearSVC(C=1.0, class_weight=\"balanced\")\n",
    "    ),\n",
    "    \"CompNB_word\" : make_pipeline(\n",
    "        word_tfidf,\n",
    "        ComplementNB()\n",
    "    ),\n",
    "    # hybrid word+char union\n",
    "    \"LogReg_word+char\" : make_pipeline(\n",
    "        FeatureUnion([(\"word\", word_tfidf), (\"char\", char_tfidf)]),\n",
    "        LogisticRegression(max_iter=1000, class_weight=\"balanced\", C=2.0)\n",
    "    ),\n",
    "}\n",
    "\n",
    "for name, model in baselines.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "- Performance on single class isnt that good from simple baseline models\n",
    "- Logistic Regression on words only tfidf performs best. pefromance worsens when adding in characters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Baseline with OneVsRest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((318, 9), (80, 9))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train_r = train_df[\"text\"].values, train_df[\"labels\"].values\n",
    "\n",
    "X_test, y_test_r = test_df[\"text\"].values, test_df[\"labels\"].values\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "y_train = mlb.fit_transform(y_train_r)\n",
    "y_test = mlb.transform(y_test_r)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_vec = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        max_df=0.9,\n",
    "        min_df=5,\n",
    "        ngram_range=(1,2),\n",
    "        dtype=np.float32\n",
    "    )),\n",
    "    (\"svd\", TruncatedSVD(n_components=100, random_state=RANDOM))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVR_LogReg       micro-F1: 0.553  macro-F1: 0.559  subset-Acc: 0.300\n",
      "OVR_LinearSVC    micro-F1: 0.556  macro-F1: 0.571  subset-Acc: 0.338\n",
      "OVR_RF_500       micro-F1: 0.060  macro-F1: 0.042  subset-Acc: 0.037\n",
      "OVR_XGB          micro-F1: 0.328  macro-F1: 0.251  subset-Acc: 0.250\n"
     ]
    }
   ],
   "source": [
    "multi_clfs = {\n",
    "    \"OVR_LogReg\": LogisticRegression(max_iter=1000, C=2.0, class_weight=\"balanced\", random_state=RANDOM),\n",
    "    \"OVR_LinearSVC\": LinearSVC(C=1.0, class_weight=\"balanced\", random_state=RANDOM),\n",
    "\n",
    "    \"OVR_RF_500\": RandomForestClassifier(random_state=RANDOM),\n",
    "    \"OVR_XGB\": XGBClassifier(random_state=RANDOM),\n",
    "    # \"OVR_LGBM\": LGBMClassifier(random_state=RANDOM, class_weight = 'balanced', verbose = -1)\n",
    "\n",
    "}\n",
    "\n",
    "plot = False\n",
    "\n",
    "for name, base_clf in multi_clfs.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"vec\", dense_vec),\n",
    "        (\"clf\", OneVsRestClassifier(base_clf, n_jobs=-1))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    micro  = f1_score(y_test, y_pred, average=\"micro\")\n",
    "    macro  = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    subset = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{name:15s}  micro-F1: {micro:.3f}  macro-F1: {macro:.3f}  subset-Acc: {subset:.3f}\")\n",
    "\n",
    "    if plot:\n",
    "        actual_counts = np.array(y_test).sum(axis=0)\n",
    "        pred_counts = np.array(y_pred).sum(axis=0)\n",
    "        labels = mlb.classes_\n",
    "\n",
    "        mcm = multilabel_confusion_matrix(y_test, y_pred)\n",
    "        top_idxs = np.argsort(actual_counts)[-10:]\n",
    "\n",
    "        fig, axes = plt.subplots(1, len(top_idxs), figsize=(4*len(top_idxs), 4))\n",
    "        for ax, idx in zip(axes, top_idxs):\n",
    "            sns.heatmap(mcm[idx], annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "            ax.set_title(f\"Class: {labels[idx]}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline ===\n",
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "                                   None       0.39      0.52      0.45        25\n",
      "                epidemics_and_pandemics       0.62      0.83      0.71         6\n",
      "                     financial_distress       0.50      0.57      0.53         7\n",
      "                      financial_success       0.25      0.25      0.25         4\n",
      "                    geopolitical_issues       0.57      0.44      0.50         9\n",
      "                            investments       0.40      0.50      0.44         8\n",
      "labor_workforce_compliance_human_rights       0.80      0.73      0.76        11\n",
      "                      natural_disasters       0.62      0.83      0.71         6\n",
      "                            supplychain       0.67      0.67      0.67        12\n",
      "\n",
      "                              micro avg       0.52      0.59      0.55        88\n",
      "                              macro avg       0.54      0.59      0.56        88\n",
      "                           weighted avg       0.53      0.59      0.56        88\n",
      "                            samples avg       0.48      0.61      0.52        88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/document-tagger/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "baseline = Pipeline([\n",
    "    (\"vec\", dense_vec),\n",
    "    (\"clf\", OneVsRestClassifier(LogisticRegression(max_iter=1000, C=2.0, class_weight=\"balanced\", random_state=RANDOM), n_jobs=-1))\n",
    "])\n",
    "\n",
    "baseline.fit(X_train, y_train)\n",
    "y_pred = baseline.predict(X_test)\n",
    "print(f\"\\n=== Baseline ===\")        \n",
    "baselien_report = classification_report(y_test, y_pred, target_names=mlb.classes_)\n",
    "print(baselien_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "Baseline Logistic Regression model has micro-f1 of .55. this is still not very good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-multilearn similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((318, 9), (80, 9))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train_r = train_df[\"text\"].values, train_df[\"labels\"].values\n",
    "\n",
    "X_test, y_test_r = test_df[\"text\"].values, test_df[\"labels\"].values\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "y_train = mlb.fit_transform(y_train_r)\n",
    "y_test = mlb.transform(y_test_r)\n",
    "y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "                                   None       0.42      0.40      0.41        25\n",
      "                epidemics_and_pandemics       0.33      0.17      0.22         6\n",
      "                     financial_distress       0.25      0.14      0.18         7\n",
      "                      financial_success       0.25      0.25      0.25         4\n",
      "                    geopolitical_issues       0.33      0.33      0.33         9\n",
      "                            investments       1.00      0.12      0.22         8\n",
      "labor_workforce_compliance_human_rights       0.67      0.18      0.29        11\n",
      "                      natural_disasters       0.40      0.33      0.36         6\n",
      "                            supplychain       0.67      0.50      0.57        12\n",
      "\n",
      "                              micro avg       0.44      0.31      0.36        88\n",
      "                              macro avg       0.48      0.27      0.32        88\n",
      "                           weighted avg       0.50      0.31      0.35        88\n",
      "                            samples avg       0.33      0.32      0.32        88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/document-tagger/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors as _NN\n",
    "import skmultilearn.adapt.mlknn as _mlknn\n",
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "_mlknn.NearestNeighbors = lambda n_neighbors, **kw: _NN(n_neighbors=n_neighbors, **kw)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"vec\", dense_vec),\n",
    "    (\"clf\", MLkNN(k=3))\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "dlr = classification_report(y_test, y_pred, target_names=mlb.classes_)\n",
    "\n",
    "print(dlr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway\n",
    "\n",
    "Does not outperform baseline and requires hot fix to revert to older version of sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreTrained Sentence Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/document-tagger/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/document-tagger/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embed shape: (318, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "X_tr_sbert = embedder.encode(X_train, \n",
    "                             batch_size=32, \n",
    "                             show_progress_bar=False, \n",
    "                             convert_to_numpy=True)\n",
    "\n",
    "X_te_sbert = embedder.encode(X_test,  \n",
    "                             batch_size=32, \n",
    "                             show_progress_bar=False, \n",
    "                             convert_to_numpy=True)\n",
    "\n",
    "print(\"Train embed shape:\", X_tr_sbert.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "                                   None       0.44      0.68      0.53        25\n",
      "                epidemics_and_pandemics       0.57      0.67      0.62         6\n",
      "                     financial_distress       0.35      0.86      0.50         7\n",
      "                      financial_success       0.31      1.00      0.47         4\n",
      "                    geopolitical_issues       0.47      0.78      0.58         9\n",
      "                            investments       0.40      0.75      0.52         8\n",
      "labor_workforce_compliance_human_rights       0.64      0.82      0.72        11\n",
      "                      natural_disasters       0.45      0.83      0.59         6\n",
      "                            supplychain       0.44      0.67      0.53        12\n",
      "\n",
      "                              micro avg       0.44      0.75      0.56        88\n",
      "                              macro avg       0.45      0.78      0.56        88\n",
      "                           weighted avg       0.46      0.75      0.56        88\n",
      "                            samples avg       0.48      0.76      0.56        88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/document-tagger/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        C=.1\n",
    "    ), \n",
    "    n_jobs=-1\n",
    ")\n",
    "clf.fit(X_tr_sbert, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_te_sbert)\n",
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway\n",
    "Performance did improve. Concerned about model complexity now with so many features and so few documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "                                   None       0.42      0.64      0.51        25\n",
      "                epidemics_and_pandemics       0.57      0.67      0.62         6\n",
      "                     financial_distress       0.33      0.86      0.48         7\n",
      "                      financial_success       0.31      1.00      0.47         4\n",
      "                    geopolitical_issues       0.47      0.78      0.58         9\n",
      "                            investments       0.40      0.75      0.52         8\n",
      "labor_workforce_compliance_human_rights       0.64      0.82      0.72        11\n",
      "                      natural_disasters       0.45      0.83      0.59         6\n",
      "                            supplychain       0.39      0.58      0.47        12\n",
      "\n",
      "                              micro avg       0.43      0.73      0.54        88\n",
      "                              macro avg       0.44      0.77      0.55        88\n",
      "                           weighted avg       0.45      0.73      0.55        88\n",
      "                            samples avg       0.46      0.74      0.54        88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/document-tagger/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100, random_state=42)\n",
    "X_tr_pca = pca.fit_transform(X_tr_sbert)\n",
    "X_te_pca = pca.transform(X_te_sbert)\n",
    "\n",
    "clf = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=RANDOM,\n",
    "        C=.1\n",
    "    ), \n",
    "    n_jobs=-1\n",
    ")\n",
    "clf.fit(X_tr_pca, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_te_pca)\n",
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway\n",
    "Dont loose too much signal by reducing feature space. Worth considering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "document-tagger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
