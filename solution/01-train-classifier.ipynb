{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, joblib\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a class to wrap encoder so that it can be pickeled with the rest of the pipeline\n",
    "class SbertEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\", batch_size=32, device=None):\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self._model = None\n",
    "    def _m(self):\n",
    "        if self._model is None:\n",
    "            self._model = SentenceTransformer(self.model_name, device=self.device)\n",
    "        return self._model\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        return np.asarray(\n",
    "            self._m().encode(X, batch_size=self.batch_size,\n",
    "                             show_progress_bar=False, convert_to_numpy=True)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH  = Path(\"../data/craft-ml-data.jsonl\")\n",
    "ART_DIR    = Path(\"artifacts\"); ART_DIR.mkdir(exist_ok=True)\n",
    "PIPE_PATH  = ART_DIR / \"pipeline.joblib\"\n",
    "MLB_PATH   = ART_DIR / \"mlb.joblib\"\n",
    "TAU_PATH   = ART_DIR / \"tau.txt\"\n",
    "RANDOM     = 42\n",
    "CV_FOLDS   = 5\n",
    "TAU_GRID   = np.linspace(0.1, 0.90, 20)\n",
    "WRITE = True\n",
    "FILL_LABELS = False\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 labelled docs | 8 classes\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(DATA_PATH, lines=True)\n",
    "df = df.loc[df[\"text\"].notna() & df[\"labels\"].notna()].reset_index(drop=True)\n",
    "\n",
    "if FILL_LABELS:\n",
    "    df[\"labels\"] = df[\"labels\"].apply(\n",
    "    lambda lbls: lbls if (isinstance(lbls, list) and len(lbls) > 0) else [\"none\"]\n",
    "    )\n",
    "\n",
    "X_raw = df[\"text\"].tolist()\n",
    "y_raw = df[\"labels\"].tolist()\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_all = mlb.fit_transform(y_raw)\n",
    "mask   = Y_all.sum(1) > 0\n",
    "X_lab  = [X_raw[i] for i,m in enumerate(mask) if m]\n",
    "Y_lab  = Y_all[mask]\n",
    "\n",
    "unlab_mask  = ~mask\n",
    "X_unlab     = [X_raw[i] for i, m in enumerate(unlab_mask) if m]\n",
    "\n",
    "print(f\"{len(X_lab):,} labelled docs | {Y_lab.shape[1]} classes\")\n",
    "\n",
    "strat_y = np.where(Y_lab.sum(1)==1, Y_lab.argmax(1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Pipeline\n",
    "base_pipe = Pipeline([\n",
    "    (\"sbert\",  SbertEncoder(batch_size=32)),\n",
    "    (\"scale\",  StandardScaler(with_mean=False)),\n",
    "    (\"clf\",    OneVsRestClassifier(\n",
    "                   LogisticRegression(max_iter=1000,\n",
    "                                      C=0.1,\n",
    "                                      random_state=RANDOM)\n",
    "                                      )\n",
    "    ),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross fold training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/document-tagger/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/document-tagger/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0:  macro-F1=0.626  micro-F1=0.621\n",
      "fold 1:  macro-F1=0.536  micro-F1=0.552\n",
      "fold 2:  macro-F1=0.479  micro-F1=0.522\n",
      "fold 3:  macro-F1=0.578  micro-F1=0.590\n",
      "fold 4:  macro-F1=0.572  micro-F1=0.565\n",
      "\n",
      "Per-class τ: [0.25 0.15 0.18 0.46 0.19 0.13 0.13 0.4 ]\n",
      "CV macro-F1=0.558  micro-F1=0.570\n"
     ]
    }
   ],
   "source": [
    "\n",
    "CLASS_COUNT  = Y_lab.shape[1]\n",
    "VAL_FRAC     = 0.20\n",
    "\n",
    "skf = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM)\n",
    "\n",
    "oof_proba = np.zeros_like(Y_lab, dtype=float)\n",
    "oof_pred  = np.zeros_like(Y_lab, dtype=int)\n",
    "oof_tau   = np.zeros_like(Y_lab, dtype=float)\n",
    "\n",
    "taus_folds   = []\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (tr_idx, te_idx) in enumerate(skf.split(X_lab, strat_y)):\n",
    "\n",
    "    # Fold level split\n",
    "    X_tr_all  = [X_lab[i] for i in tr_idx]\n",
    "    Y_tr_all  = Y_lab[tr_idx]\n",
    "    X_te      = [X_lab[i] for i in te_idx]\n",
    "    Y_te      = Y_lab[te_idx]\n",
    "\n",
    "    # Within fold split for threshold tuning\n",
    "    strat_inner = np.where(Y_tr_all.sum(1)==1,\n",
    "                           Y_tr_all.argmax(1), -1)\n",
    "    X_tr, X_val, Y_tr, Y_val = train_test_split(\n",
    "        X_tr_all, Y_tr_all,\n",
    "        test_size   = VAL_FRAC,\n",
    "        stratify    = strat_inner,\n",
    "        random_state= RANDOM)\n",
    "\n",
    "\n",
    "    pipe_inner  = base_pipe.fit(X_tr, Y_tr)\n",
    "    proba_val   = pipe_inner.predict_proba(X_val)\n",
    "\n",
    "    # learn best threshold per class\n",
    "    best_taus_fold = np.zeros(CLASS_COUNT)\n",
    "    for c in range(CLASS_COUNT):\n",
    "        f1_by_t = [\n",
    "            f1_score(Y_val[:, c],\n",
    "                     (proba_val[:, c] >= t).astype(int),\n",
    "                     average=\"binary\", zero_division=0)\n",
    "            for t in TAU_GRID\n",
    "        ]\n",
    "        best_taus_fold[c] = TAU_GRID[int(np.argmax(f1_by_t))]\n",
    "\n",
    "    # Fit on full-fold train with that vector\n",
    "    pipe = base_pipe.fit(X_tr_all, Y_tr_all)\n",
    "    proba_te = pipe.predict_proba(X_te)\n",
    "    Y_pred   = (proba_te >= best_taus_fold).astype(int)\n",
    "\n",
    "\n",
    "    # Save Predictions\n",
    "    oof_proba[te_idx] = proba_te\n",
    "    oof_pred [te_idx] = Y_pred\n",
    "    oof_tau  [te_idx] = best_taus_fold\n",
    "\n",
    "    macro_f1 = f1_score(Y_te, Y_pred,\n",
    "                        average=\"macro\", zero_division=0)\n",
    "    micro_f1 = f1_score(Y_te, Y_pred,\n",
    "                        average=\"micro\", zero_division=0)\n",
    "    \n",
    "    fold_metrics.append((macro_f1, micro_f1))\n",
    "    taus_folds.append(best_taus_fold)\n",
    "\n",
    "    print(f\"fold {fold}:  macro-F1={macro_f1:.3f}  micro-F1={micro_f1:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "taus_folds = np.stack(taus_folds)\n",
    "tau_vec    = taus_folds.mean(0)\n",
    "print(\"\\nPer-class τ:\", np.round(tau_vec, 2))\n",
    "\n",
    "macro_cv, micro_cv = np.mean(fold_metrics, axis=0)\n",
    "print(f\"CV macro-F1={macro_cv:.3f}  micro-F1={micro_cv:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "                epidemics_and_pandemics      0.528     0.559     0.543        34\n",
      "                     financial_distress      0.373     0.564     0.449        39\n",
      "                      financial_success      0.471     0.706     0.565        34\n",
      "                    geopolitical_issues      0.655     0.528     0.585        36\n",
      "                            investments      0.414     0.600     0.490        40\n",
      "labor_workforce_compliance_human_rights      0.558     0.774     0.649        31\n",
      "                      natural_disasters      0.809     0.927     0.864        41\n",
      "                            supplychain      0.462     0.439     0.450        41\n",
      "\n",
      "                              micro avg      0.519     0.635     0.571       296\n",
      "                              macro avg      0.534     0.637     0.574       296\n",
      "                           weighted avg      0.534     0.635     0.574       296\n",
      "                            samples avg      0.538     0.649     0.564       296\n",
      "\n",
      "\n",
      "Macro-F1: 0.574   |   Micro-F1: 0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/document-tagger/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Out of fold evaluation\n",
    "print(classification_report(\n",
    "        Y_lab,  \n",
    "        oof_pred,\n",
    "        target_names=mlb.classes_, \n",
    "        digits=3\n",
    "))\n",
    "\n",
    "macro_f1 = f1_score(Y_lab, oof_pred, average=\"macro\", zero_division=0)\n",
    "micro_f1 = f1_score(Y_lab, oof_pred, average=\"micro\", zero_division=0)\n",
    "\n",
    "print(f\"\\nMacro-F1: {macro_f1:.3f}   |   Micro-F1: {micro_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/137 unlabelled docs (85.4%) received at least one tag\n"
     ]
    }
   ],
   "source": [
    "final_pipe = base_pipe.fit(X_lab, Y_lab)\n",
    "\n",
    "if not FILL_LABELS:\n",
    "      proba_unlab = final_pipe.predict_proba(X_unlab)\n",
    "      pred_unlab  = (proba_unlab >= tau_vec).astype(int)\n",
    "\n",
    "      n_unlab = pred_unlab.shape[0]\n",
    "      hits_per_doc = pred_unlab.sum(1)\n",
    "      n_predicted_any = int((hits_per_doc > 0).sum())\n",
    "      print(f\"{n_predicted_any}/{n_unlab} unlabelled docs \"\n",
    "            f\"({n_predicted_any / n_unlab:.1%}) received at least one tag\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipe = base_pipe.fit(X_lab, Y_lab)\n",
    "\n",
    "# This will only run on a fresh kernal. Run all cells at once for model to be saved propperly.\n",
    "if WRITE:\n",
    "    joblib.dump(final_pipe, PIPE_PATH, compress=3)\n",
    "    joblib.dump(mlb,       MLB_PATH,  compress=3)\n",
    "    np.save(ART_DIR / \"tau_vec.npy\",   tau_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- The model is too \"Excited\" to identify things right now. Need to take some steps to be more conservative in classification. This is probably due to the imbalance of the data.\n",
    "- More advanced methods would likely perform better here, but we do not have a large amoutn of data to use with those mthods\n",
    "- More work on word embedding could be done. Only looked at TF-IDF and sentance transformer.\n",
    "- There may be some value in feature reduction here as well \n",
    "- Need to understand business context on \"cost\" of misclassification to inform how model is tuned and evaluated\n",
    "- Approaching this as a document similarity task instead of one vs all classification may be one way to handle the issues arising from the diverse unlabled class  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "document-tagger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
